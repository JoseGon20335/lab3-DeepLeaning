{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, SimpleRNN, LSTM\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(url, split_percent=0.8):\n",
    "    df = pd.read_csv(url, usecols=[1], engine='python')\n",
    "    data = np.array(df.values.astype('float32'))\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    data = scaler.fit_transform(data).flatten()\n",
    "    n = len(data)\n",
    "    split = int(n * split_percent)\n",
    "    train_data = data[:split]\n",
    "    test_data = data[split:]\n",
    "    return train_data, test_data, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feedforward_nn(input_shape, activation):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(64, input_shape=input_shape, activation=activation))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(32, activation=activation))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(1, activation=activation))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rnn_model(hidden_units, dense_units, input_shape, activation):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(SimpleRNN(hidden_units, input_shape=input_shape, activation=activation))\n",
    "\n",
    "    model.add(Dense(units=dense_units, activation=activation))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_lstm_model(hidden_units, dense_units, input_shape, activation):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(hidden_units, input_shape=input_shape, activation=activation))\n",
    "\n",
    "    model.add(Dense(units=dense_units, activation=activation))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sequence_data(dat, time_steps):\n",
    "    indY = np.arange(time_steps, len(dat), time_steps)\n",
    "    Y = dat[indY]\n",
    "\n",
    "    rowsX = len(Y)\n",
    "    X = dat[range(time_steps * rowsX)]\n",
    "    X = np.reshape(X, (rowsX, time_steps, 1))\n",
    "\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_and_print_metrics(trainY, testY, trainPredict, testPredict):\n",
    "    train_rmse = math.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "    test_rmse = math.sqrt(mean_squared_error(testY, testPredict))\n",
    "    train_r2 = r2_score(trainY, trainPredict)\n",
    "    test_r2 = r2_score(testY, testPredict)\n",
    "\n",
    "    print('Train RMSE: %.3f' % train_rmse)\n",
    "    print('Test RMSE: %.3f' % test_rmse)\n",
    "    print('Train R2: %.3f' % train_r2)\n",
    "    print('Test R2: %.3f' % test_r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "187/187 - 1s - loss: 0.0492 - 1s/epoch - 7ms/step\n",
      "Epoch 2/20\n",
      "187/187 - 0s - loss: 0.0492 - 327ms/epoch - 2ms/step\n",
      "Epoch 3/20\n",
      "187/187 - 0s - loss: 0.0492 - 257ms/epoch - 1ms/step\n",
      "Epoch 4/20\n",
      "187/187 - 0s - loss: 0.0492 - 266ms/epoch - 1ms/step\n",
      "Epoch 5/20\n",
      "187/187 - 0s - loss: 0.0492 - 245ms/epoch - 1ms/step\n",
      "Epoch 6/20\n",
      "187/187 - 0s - loss: 0.0492 - 247ms/epoch - 1ms/step\n",
      "Epoch 7/20\n",
      "187/187 - 0s - loss: 0.0492 - 226ms/epoch - 1ms/step\n",
      "Epoch 8/20\n",
      "187/187 - 0s - loss: 0.0492 - 219ms/epoch - 1ms/step\n",
      "Epoch 9/20\n",
      "187/187 - 0s - loss: 0.0492 - 217ms/epoch - 1ms/step\n",
      "Epoch 10/20\n",
      "187/187 - 0s - loss: 0.0492 - 218ms/epoch - 1ms/step\n",
      "Epoch 11/20\n",
      "187/187 - 0s - loss: 0.0492 - 221ms/epoch - 1ms/step\n",
      "Epoch 12/20\n",
      "187/187 - 0s - loss: 0.0492 - 224ms/epoch - 1ms/step\n",
      "Epoch 13/20\n",
      "187/187 - 0s - loss: 0.0492 - 223ms/epoch - 1ms/step\n",
      "Epoch 14/20\n",
      "187/187 - 0s - loss: 0.0492 - 272ms/epoch - 1ms/step\n",
      "Epoch 15/20\n",
      "187/187 - 0s - loss: 0.0492 - 362ms/epoch - 2ms/step\n",
      "Epoch 16/20\n",
      "187/187 - 0s - loss: 0.0492 - 222ms/epoch - 1ms/step\n",
      "Epoch 17/20\n",
      "187/187 - 0s - loss: 0.0492 - 389ms/epoch - 2ms/step\n",
      "Epoch 18/20\n",
      "187/187 - 0s - loss: 0.0492 - 275ms/epoch - 1ms/step\n",
      "Epoch 19/20\n",
      "187/187 - 0s - loss: 0.0492 - 363ms/epoch - 2ms/step\n",
      "Epoch 20/20\n",
      "187/187 - 0s - loss: 0.0492 - 268ms/epoch - 1ms/step\n",
      "Epoch 1/20\n",
      "187/187 - 1s - loss: 0.0820 - 1s/epoch - 8ms/step\n",
      "Epoch 2/20\n",
      "187/187 - 0s - loss: 0.0353 - 400ms/epoch - 2ms/step\n",
      "Epoch 3/20\n",
      "187/187 - 0s - loss: 0.0245 - 392ms/epoch - 2ms/step\n",
      "Epoch 4/20\n",
      "187/187 - 1s - loss: 0.0171 - 677ms/epoch - 4ms/step\n",
      "Epoch 5/20\n",
      "187/187 - 0s - loss: 0.0119 - 419ms/epoch - 2ms/step\n",
      "Epoch 6/20\n",
      "187/187 - 1s - loss: 0.0087 - 540ms/epoch - 3ms/step\n",
      "Epoch 7/20\n",
      "187/187 - 0s - loss: 0.0065 - 422ms/epoch - 2ms/step\n",
      "Epoch 8/20\n",
      "187/187 - 0s - loss: 0.0051 - 425ms/epoch - 2ms/step\n",
      "Epoch 9/20\n",
      "187/187 - 0s - loss: 0.0047 - 445ms/epoch - 2ms/step\n",
      "Epoch 10/20\n",
      "187/187 - 0s - loss: 0.0046 - 481ms/epoch - 3ms/step\n",
      "Epoch 11/20\n",
      "187/187 - 0s - loss: 0.0045 - 378ms/epoch - 2ms/step\n",
      "Epoch 12/20\n",
      "187/187 - 0s - loss: 0.0045 - 373ms/epoch - 2ms/step\n",
      "Epoch 13/20\n",
      "187/187 - 0s - loss: 0.0044 - 380ms/epoch - 2ms/step\n",
      "Epoch 14/20\n",
      "187/187 - 0s - loss: 0.0044 - 438ms/epoch - 2ms/step\n",
      "Epoch 15/20\n",
      "187/187 - 0s - loss: 0.0043 - 414ms/epoch - 2ms/step\n",
      "Epoch 16/20\n",
      "187/187 - 0s - loss: 0.0042 - 435ms/epoch - 2ms/step\n",
      "Epoch 17/20\n",
      "187/187 - 0s - loss: 0.0042 - 383ms/epoch - 2ms/step\n",
      "Epoch 18/20\n",
      "187/187 - 0s - loss: 0.0041 - 371ms/epoch - 2ms/step\n",
      "Epoch 19/20\n",
      "187/187 - 0s - loss: 0.0041 - 371ms/epoch - 2ms/step\n",
      "Epoch 20/20\n",
      "187/187 - 0s - loss: 0.0040 - 427ms/epoch - 2ms/step\n",
      "Epoch 1/20\n",
      "187/187 - 3s - loss: 0.1003 - 3s/epoch - 16ms/step\n",
      "Epoch 2/20\n",
      "187/187 - 1s - loss: 0.0410 - 606ms/epoch - 3ms/step\n",
      "Epoch 3/20\n",
      "187/187 - 1s - loss: 0.0274 - 585ms/epoch - 3ms/step\n",
      "Epoch 4/20\n",
      "187/187 - 1s - loss: 0.0179 - 606ms/epoch - 3ms/step\n",
      "Epoch 5/20\n",
      "187/187 - 1s - loss: 0.0109 - 598ms/epoch - 3ms/step\n",
      "Epoch 6/20\n",
      "187/187 - 1s - loss: 0.0073 - 598ms/epoch - 3ms/step\n",
      "Epoch 7/20\n",
      "187/187 - 1s - loss: 0.0062 - 619ms/epoch - 3ms/step\n",
      "Epoch 8/20\n",
      "187/187 - 1s - loss: 0.0058 - 588ms/epoch - 3ms/step\n",
      "Epoch 9/20\n",
      "187/187 - 1s - loss: 0.0056 - 577ms/epoch - 3ms/step\n",
      "Epoch 10/20\n",
      "187/187 - 1s - loss: 0.0056 - 592ms/epoch - 3ms/step\n",
      "Epoch 11/20\n",
      "187/187 - 1s - loss: 0.0054 - 586ms/epoch - 3ms/step\n",
      "Epoch 12/20\n",
      "187/187 - 1s - loss: 0.0054 - 577ms/epoch - 3ms/step\n",
      "Epoch 13/20\n",
      "187/187 - 1s - loss: 0.0052 - 620ms/epoch - 3ms/step\n",
      "Epoch 14/20\n",
      "187/187 - 1s - loss: 0.0049 - 602ms/epoch - 3ms/step\n",
      "Epoch 15/20\n",
      "187/187 - 1s - loss: 0.0049 - 580ms/epoch - 3ms/step\n",
      "Epoch 16/20\n",
      "187/187 - 1s - loss: 0.0049 - 575ms/epoch - 3ms/step\n",
      "Epoch 17/20\n",
      "187/187 - 1s - loss: 0.0048 - 575ms/epoch - 3ms/step\n",
      "Epoch 18/20\n",
      "187/187 - 1s - loss: 0.0048 - 622ms/epoch - 3ms/step\n",
      "Epoch 19/20\n",
      "187/187 - 1s - loss: 0.0046 - 585ms/epoch - 3ms/step\n",
      "Epoch 20/20\n",
      "187/187 - 1s - loss: 0.0046 - 571ms/epoch - 3ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "6/6 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "6/6 [==============================] - 1s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "\n",
      "Feedforward NN\n",
      "Train RMSE: 0.222\n",
      "Test RMSE: 0.360\n",
      "Train R2: -1.350\n",
      "Test R2: -1.809\n",
      "Training Time: 6.54 seconds\n",
      "\n",
      "RNN Model\n",
      "Train RMSE: 0.063\n",
      "Test RMSE: 0.099\n",
      "Train R2: 0.812\n",
      "Test R2: 0.788\n",
      "Training Time: 9.74 seconds\n",
      "\n",
      "LSTM Model\n",
      "Train RMSE: 0.066\n",
      "Test RMSE: 0.100\n",
      "Train R2: 0.790\n",
      "Test R2: 0.782\n",
      "Training Time: 14.36 seconds\n"
     ]
    }
   ],
   "source": [
    "time_steps = 12\n",
    "sunspot_data_url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/monthly-sunspots.csv'\n",
    "train_data, test_data, all_data = load_and_preprocess_data(sunspot_data_url)\n",
    "\n",
    "train_X, train_Y = prepare_sequence_data(train_data, time_steps)\n",
    "test_X, test_Y = prepare_sequence_data(test_data, time_steps)\n",
    "\n",
    "nn_model = create_feedforward_nn(input_shape=(time_steps, 1), activation='relu')\n",
    "rnn_model = create_rnn_model(hidden_units=3, dense_units=1, input_shape=(time_steps, 1), activation='tanh')\n",
    "lstm_model = create_lstm_model(hidden_units=3, dense_units=1, input_shape=(time_steps, 1), activation='tanh')\n",
    "\n",
    "time_start_nn = time.time()\n",
    "nn_model.fit(train_X, train_Y, epochs=20, batch_size=1, verbose=2)\n",
    "time_end_nn = time.time()\n",
    "\n",
    "time_start_rnn = time.time()\n",
    "rnn_model.fit(train_X, train_Y, epochs=20, batch_size=1, verbose=2)\n",
    "time_end_rnn = time.time()\n",
    "\n",
    "time_start_lstm = time.time()\n",
    "lstm_model.fit(train_X, train_Y, epochs=20, batch_size=1, verbose=2)\n",
    "time_end_lstm = time.time()\n",
    "\n",
    "train_predict_nn = nn_model.predict(train_X)\n",
    "test_predict_nn = nn_model.predict(test_X)\n",
    "\n",
    "train_predict_rnn = rnn_model.predict(train_X)\n",
    "test_predict_rnn = rnn_model.predict(test_X)\n",
    "\n",
    "train_predict_lstm = lstm_model.predict(train_X)\n",
    "test_predict_lstm = lstm_model.predict(test_X)\n",
    "\n",
    "print('\\nFeedforward NN')\n",
    "evaluate_and_print_metrics(train_Y, test_Y, train_predict_nn, test_predict_nn)\n",
    "print('Training Time: %.2f seconds' % (time_end_nn - time_start_nn))\n",
    "\n",
    "print('\\nRNN Model')\n",
    "evaluate_and_print_metrics(train_Y, test_Y, train_predict_rnn, test_predict_rnn)\n",
    "print('Training Time: %.2f seconds' % (time_end_rnn - time_start_rnn))\n",
    "\n",
    "print('\\nLSTM Model')\n",
    "evaluate_and_print_metrics(train_Y, test_Y, train_predict_lstm, test_predict_lstm)\n",
    "print('Training Time: %.2f seconds' % (time_end_lstm - time_start_lstm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (NN):\n",
    "\n",
    "### Ventajas:\n",
    "\n",
    "Es mas simple de utilzar, ademas que esta puede funcionar de mejor manera con problemas mas sencillos, con una relacion entre entradas y salidas simples o con patrones no tan complejos. Ademas que el entrenamiento de este es mucho mas simple y veloz en comparacion con las otras dos redes\n",
    "\n",
    "### Desventajas\n",
    "\n",
    "Este no tiene una capacidad de retencion propieamente dicho, osea que no puede capturar los patrones de forma real. Ademas que este no es muy adecuado para secuencias, porque esta no maneja datos de series temporales de forma buena por lo antes mencionado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (RNN):\n",
    "\n",
    "### Pros:\n",
    "\n",
    "Las redes neuronales recurrentes están diseñadas específicamente para tratar con secuencias y tienen la capacidad de capturar dependencias temporales y patrones en datos secuenciales. Son capaces de manejar secuencias de longitud variable y pueden adaptarse a diferentes longitudes de entrada.\n",
    "\n",
    "### Cons:\n",
    "\n",
    "No obstante, las RNNs pueden sufrir del problema del gradiente desvaneciente, lo que puede dificultar su entrenamiento y afectar su capacidad para capturar patrones a largo plazo. También pueden tener dificultades para mantener dependencias a largo plazo debido a este problema. Además, el entrenamiento de RNNs puede ser más lento en comparación con las redes neuronales feedforward debido a la naturaleza secuencial de su procesamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (LSTM):\n",
    "\n",
    "### Pros:\n",
    "\n",
    "Las redes LSTM se destacan en capturar dependencias a largo plazo en secuencias, abordando el problema del gradiente desvaneciente presente en RNNs tradicionales. Tienen la capacidad de retener información y patrones en secuencias más largas, lo que las hace ideales para datos secuenciales complejos.\n",
    "\n",
    "### Cons:\n",
    "\n",
    "Sin embargo, las LSTMs son más complejas que las RNNs y las redes neuronales feedforward básicas, lo que puede resultar en tiempos de entrenamiento más prolongados. Si no se regularizan adecuadamente, las LSTMs pueden sobreajustar en conjuntos de datos pequeños."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basándonos en los resultados de evaluación y consideraciones teóricas, la arquitectura LSTM parece ser la elección más adecuada para resolver el problema de pronóstico de manchas solares. Aunque las LSTMs pueden tener un tiempo de entrenamiento más largo, su capacidad para capturar patrones complejos y dependencias temporales en los datos es fundamental para un pronóstico preciso. Dado que el conjunto de datos de manchas solares implica relaciones secuenciales significativas, la arquitectura LSTM es altamente apropiada para este caso."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
